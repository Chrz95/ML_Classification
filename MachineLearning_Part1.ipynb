{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Χρήστος Ζαχαριουδάκης - 03400132 - ΕΔΕΜΜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdAzUcze-dGA"
   },
   "source": [
    "# Επιβλεπόμενη μάθηση: μελέτη dataset του αποθετηρίου OpenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gbXQMng-0xH"
   },
   "source": [
    "## **Ανάγνωση και επισκόπηση του dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODm8i_3_52Hv"
   },
   "source": [
    "Στην αρχή της εργασίας θα φορτώσουμε το dataset **OML16**, από το αποθετήριο Μηχανικής Μάθησης **OpenML**, χρησιμοποιώντας το πακέτο **openml** της **Python**. Πριν γίνει αυτό, πρέπει να εγγραφούμε στην ιστοσελίδα [OpenML](https://www.openml.org/) και να αποκτήσουμε προσωπικό κλειδί API. Αφού γίνει αυτό, εκτελούμε τον παρακάτω κώδικα για να κατεβάσουμε το πακέτο **openml**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EyRJRJgt6vH5",
    "outputId": "9d034333-50e3-4a5d-cfbc-c3a37a740ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openml\n",
      "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (0.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (2.26.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (0.24.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (1.3.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.6.2 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from openml) (1.21.5)\n",
      "Collecting minio\n",
      "  Downloading minio-7.1.2-py3-none-any.whl (75 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-6.0.1-cp39-cp39-win_amd64.whl (15.5 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->openml) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from python-dateutil->openml) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->openml) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->openml) (1.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from minio->openml) (2021.10.8)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from minio->openml) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from requests->openml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xrigi\\anaconda3\\lib\\site-packages (from requests->openml) (3.2)\n",
      "Building wheels for collected packages: openml, liac-arff\n",
      "  Building wheel for openml (setup.py): started\n",
      "  Building wheel for openml (setup.py): finished with status 'done'\n",
      "  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137327 sha256=017fc8da6923f7404fc43242bf027c3e0ae318bc8de673e5ce428d1cd7806400\n",
      "  Stored in directory: c:\\users\\xrigi\\appdata\\local\\pip\\cache\\wheels\\bc\\16\\10\\f542aa38a32dfbdec03e4bb3c68b69dbbae98a013107333b39\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=8e998300ff4dfdb5b3db7f196af93e67795cc71e92ff44e89b731abfbd1ccab6\n",
      "  Stored in directory: c:\\users\\xrigi\\appdata\\local\\pip\\cache\\wheels\\08\\82\\8b\\5c514221984e88c059b94e36a71d4722e590acaae04deab22e\n",
      "Successfully built openml liac-arff\n",
      "Installing collected packages: pyarrow, minio, liac-arff, openml\n",
      "Successfully installed liac-arff-2.5.0 minio-7.1.2 openml-0.12.2 pyarrow-6.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIlF1vC7_XLp"
   },
   "source": [
    "Έπειτα χρησιμοποιούμε το πακέτο για να κατεβάσουμε το dataset, καθώς και τα μεταδεδομένα του, όπως τίτλο, περίληψη, πηγή και περιγραφή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2874,
     "status": "ok",
     "timestamp": 1639328142711,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "dj0umMpI6h4f",
    "outputId": "4e16bd5b-7d3c-4bac-8423-44fe205d0c5b"
   },
   "outputs": [],
   "source": [
    "import openml as oml\n",
    "import warnings\n",
    "\n",
    "# Suppress sklearn warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "oml.config.apikey = 'fc544883e5a68a49c217ca42f908207e'\n",
    "# Making sure we are using the right settings\n",
    "oml.config.server = 'https://www.openml.org/api/v1/xml'\n",
    "\n",
    "data_id = 16\n",
    "dataset = oml.datasets.get_dataset(data_id)\n",
    "\n",
    "Summary = \"This is dataset '{}', the target feature is '{}'\".format(dataset.name,dataset.default_target_attribute)\n",
    "URL = dataset.url\n",
    "description = dataset.description[:5000]\n",
    "print(Summary,URL,description,sep ='\\n')\n",
    "\n",
    "dataset = dataset.get_data() \n",
    "data = dataset[0]\n",
    "column_titles = dataset[3]\n",
    "print(\"\\nData has type of\",type(data))\n",
    "print(\"To dataset έχει διαστάσεις:\", data.shape)\n",
    "print(\"Attribute 1 has type of\",data[\"att1\"].dtype)\n",
    "print(\"Class has type of\",data[\"class\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZC7wCvTAlGw"
   },
   "source": [
    "Σύμφωνα με τα παραπάνω, το dataset περιέχει **2000 δείγματα**, που περιγράφουν χειρόγραφα ψηφία με χρήση **64 χαρακτηριστικών** (64 Karhunen-Love coefficients) και το καθένα ανήκει σε μία κλάση από το 0 έως το 9 ανάλογα με ποιό είναι το ψηφίο που αναπαριστά. Επομένως έχουμε συνολικά **10 κλάσεις**. \n",
    "\n",
    "Σκοπός του dataset λοιπόν είναι η αναγνώριση χειρόγραφων ψηφίων με βάση αυτά τα 64 χαρακτηριστικά. Τα δεδομένα είναι αποθηκευεμένα ήδη σε μορφή pandas.DataFrame, οπότε δεν χρειάζεται κάποια μετατροπή. Όλα τα χαρακτηριστικά ειναι τύπου float (float64) και το class τύπου category. Tα δεδομένα του dataset είναι: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1639328142719,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "CsZSCABUC9DH",
    "outputId": "bb2f3445-a8e7-4f15-e7cc-caacf79686ca"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 10, \"display.max_columns\", 6)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hpdg-eEDC0B"
   },
   "source": [
    "Όπως βλέπουμε, μέσα στο pandas.DataFrame, οι γραμμες είναι αριθμημένες και οι στήλες έχουν επικεφαλίδες της μορφής \"att**i**\", δηλαδή χαρακτηριστικό **i**. Τα χαρακτηριστικά είναι μη διατεταγμένα. Οι ετικέτες (labels) των κλάσεων βρίσκονται στην τελευταία στήλη με επιφαλίδα \"class\" και είναι με αύξουσα σείρα. Παρατηρούμε οτι η κάθε κλάση να αναπαρίσταται με τον αριθμό που αντιπροσωπεύει + 1. Δηλαδή το ψηφίο 0 ανήκει στην κλάση 1, το ψηφίο 1 στην 2 και ούτω κάθεξης. Αυτό μπορεί να προκαλέσει σύγχυση κατά την διάρκεια της εκπαίδευσης των μοντέλων που θα χρησιμοποιήσουμε, όποτε θα το αλλάξουμε:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1639328142719,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "letMFiQJGBrE",
    "outputId": "c3c0a733-6717-45af-d606-9e4ca4c19cc3"
   },
   "outputs": [],
   "source": [
    "data['class'] = data['class'].astype('int64') # Convert column type from category to integer\n",
    "ClassVal = {i+1:i for i in range(0,10)}\n",
    "data[\"class\"].replace(ClassVal, inplace=True)\n",
    "print(data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIA1UoOyIvMo"
   },
   "source": [
    "Στην συνέχεια θα ελέγξουμε για απουσιάζοντες τιμές. Τόσο η εκτύπωση του dataset, όσο και οι πληροφορίες από την [πηγή του dataset](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) μας ενημερώνουν ότι δεν υπάρχουν απουσιάζοντες τιμές. Ωστόσο θα κάνουμε επιπλέον ελέγχο:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1639328142720,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "SsoF1gwIJbNc",
    "outputId": "d012968e-edc2-43ce-ab76-f73e8c9512bd"
   },
   "outputs": [],
   "source": [
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TcOix8NLqrd"
   },
   "source": [
    "Ο παραπάνω έλεγχος επιβεβαιώνει ότι δεν έχουμε απουσιάζουσες τιμές."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "534zdYJOLrk7"
   },
   "source": [
    "Σε αυτό το σημείο έχει ενδιαφέρον να δούμε το ποσοστό των δειγμάτων που ανήκουν σε κάθε κλάση:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1639328142721,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "Y9me4u8KK86y",
    "outputId": "71002486-cfbe-4da3-dad6-87a9a7e0a534"
   },
   "outputs": [],
   "source": [
    "Percentages = data.groupby(['class']).size()/data.shape[0] * 100\n",
    "\n",
    "for index, value in Percentages.iteritems():\n",
    "    print(\"Class\",index,\": \",value,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m4ZwvdMOcyA"
   },
   "source": [
    "Βλέπουμε ότι έχουμε ένα τέλεια ισορροποιημένο dataset, με 10% των δειγμάτων σε κάθε κλάση, δηλαδή 200 δείγματα σε κάθε κλάση. Η παραπάνω πληροφορίες συνοψίζονται στον παρακάτω πίνακα markdown:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMCvq3uGCu2E"
   },
   "source": [
    "<div style=\"font-size: 50px\">\n",
    "\n",
    "| Ερώτηση| Απάντηση|\n",
    "|:-:|:-:|\n",
    "| Πρόβλημα dataset | Aναγνώριση χειρόγραφων ψηφίων με βάση 64 χαρακτηριστικά|\n",
    "|   Μετατροπές στα αρχεία        | Καμία                |\n",
    "| Πλήθος δειγμάτων | 2000 δείγματα|\n",
    "|   Πλήθος χαρακτηριστικών       | 64 χαρακτηριστικά                |\n",
    "|   Είδος χαρακτηριστικών       | Float              |\n",
    "|   Διάταξη χαρακτηριστικών       | Μη διατεταγμένα            |\n",
    "|  Επικεφαλίδες       | Υπάρχουν: {att1, ... , att64}               |\n",
    "|  Αρίθμηση       | Υπάρχει μέσω του pandas.DataFrame             |\n",
    "|  Ετικέτες       | Τελευταία κολόνα με τίτλο \"class\". Τιμές από 1 έως 10 (το αλλάξαμε σε 0 έως 9) με αύξουσα σειρά            |\n",
    "|  Απουσιάζοντες τιμές       | Δεν υπάρχουν            |\n",
    "| Πλήθος κλάσεων | 10 (μια για κάθε χειρόγραφο ψηφίο)|\n",
    "| Ισορροπία dataset | Τέλεια ισορροποιημένο (10 % δειγμάτων σε κάθε κλάση)|\n",
    "\n",
    "</div >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03yuECqfCyLI"
   },
   "source": [
    "Στην συνέχεια, θα διασπάσουμε το dataset σε δείγματα εκπαίδευσης (70% του dataset) και δοκιμής (30% του dataset) με χρήση της συνάρτησης train_test_split της βιβιοθήκης scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3045,
     "status": "ok",
     "timestamp": 1639328145754,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "rLAWMzNphJTA",
    "outputId": "bc8a296d-037d-48b9-a3f5-e340c87d87f2"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3q_kK1vWsJn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:, 'att1':'att64'], data['class'], test_size=0.30,random_state=42)\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(\"===========================\")\n",
    "#print(X_test)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlqC0q4XXpP2"
   },
   "source": [
    "Στην συνέχεια, θα εξετάσουμε την επίδοση ορισμένων ταξινομητων χώρις να εφαρμόσουμε βελτιστοποιήσεις (Επίδοση out-of-the-box), με τις παραμέτρους των ταξινομητών στις προεπιλεγμένες τους τιμές και εφαρμόζοντας ορισμένες βελτιστοποιήσεις."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmRKS0IPZh4E"
   },
   "source": [
    "## **Επίδοση out-of-the-box**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHx66s54aVS2"
   },
   "source": [
    "Οι ταξινομητές που θα μελετήσουμε είναι οι:\n",
    "\n",
    "*   Dummy\n",
    "*   Gaussian Naive Bayes\n",
    "*   K-Nearest Neighbors\n",
    "*   Logistic Regression\n",
    "*   Multi-Layer Perceptron\n",
    "*   Support Vector Machines\n",
    "\n",
    "Θα χρησιμοποιήσουμε τις υλοποιήσεις τους, από την βιβλιοθήκη του scikit-learn. Επίσης για την αξιολόγηση της επίδοσης των ταξινομητών, θα χρησιμοποιήσουμε δύο μετρικές:\n",
    "\n",
    "*   Accuracy = $\\frac{Σωστές\\;προβλέψεις}{Σύνολο\\;δειγμάτων}$\n",
    "*   F1-Score = $\\frac{2 * (precision * recall)}{(precision + recall)}$ όπου precision = Positive Predictive Value (PPV) = $\\frac{True\\;Positive}{(True\\;Positive + False\\;Positive)}$ και\n",
    "Recall = True Positive Rate (TPR) = $\\frac{True\\;Positive}{(True\\;Positive + False\\;Negative)}$\n",
    "\n",
    "τις οποίες επισης λαμβάνουμε από το scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2641,
     "status": "ok",
     "timestamp": 1639328148394,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "2ufjfMxaaxRJ",
    "outputId": "1786b69c-3a53-439c-ac68-1514543436d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Classifiers = [DummyClassifier(),GaussianNB(),KNeighborsClassifier(),LogisticRegression(),MLPClassifier(),SVC()]\n",
    "Accuracy = []\n",
    "F1_Sc = []\n",
    "Names = [\"Dummy\",\"GNB\",\"KNN\",\"LR\",\"MLP\",\"SVM\"]\n",
    "\n",
    "for i,clf in enumerate(Classifiers):\n",
    "  clf.fit(X_train, y_train)  # Train the model  \n",
    "  y_pred = clf.predict(X_test) # Make predictions on train samples (cheating)\n",
    "\n",
    "  acc = accuracy_score(y_test, y_pred) * 100\n",
    "  f1 = f1_score(y_test, y_pred, average='macro') * 100\n",
    "  Accuracy.append(acc)\n",
    "  F1_Sc.append(f1)\n",
    "  \n",
    "  # Print results\n",
    "  print(\"{}. {}:  \".format(i+1,type(clf).__name__))\n",
    "  print(\"\\tAccuracy is {:.2f} %\".format(acc))\n",
    "  print(\"\\tF1-Score is {:.2f} %\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWIQ-jD5spsJ"
   },
   "source": [
    "Παρατηρούμε εξαιρετικά αποτελέσματα (σχεδόν 100%) σε όλους τους ταξινομητές εκτός του Dummy, με την καλύτερη απόδοση να δίνεται από τον SVM classifier με πυρήνα \"rbf\". O SVM είναι ιδανικός για την ταξινόμηση δειγμάτων με πολλά χαρακτηριστικά και για αυτό το λόγο είναι αναμένόμενη η υψηλή επίδοσή του. Αντίθετα, ο Gaussian Naive Bayes υποθέτει (αφελώς) ότι τα χαρακτηριστικά των δειγμάτων είναι ανεξάρτητα και ότι τα δείγματα προέρχονται απο Gaussian κατανομή. Επόμενως λογικό είναι να έχει κάπως χαμηλότερη απόδοση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θα παρουσιάσουμε τα αποτελέσματα σε markdown table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYhVb7ndqCaI"
   },
   "source": [
    "| Classifier | Accuracy | F1-Score |\n",
    "| --- | --- | --- |\n",
    "| Dummy | 8.17% | 1.51% |\n",
    "| Gaussian Naive Bayes | 94.83% | 94.93% |\n",
    "| K-Neighbors | 97.83% | 97.79% |\n",
    "| Logistic Regression | 95.67% | 95.59% |\n",
    "| Multi-Layer Perceptron | 97.33% | 97.41% |\n",
    "| SVM | 98.17% | 98.13% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo114DkStIPj"
   },
   "source": [
    "και σε bar-plot με χρήση της βιβλιοθήκης **matplotlib**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2991,
     "status": "ok",
     "timestamp": 1639328151385,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "6GLrLWO7tuCq",
    "outputId": "3b9f9371-062d-4dc2-8ce6-e80c579a24a6"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1639328151695,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "1QeMx-TatK9o",
    "outputId": "1f74cf64-8cf2-4828-9571-148dfd59a0c4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle('Metrics on train set')\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax1.bar(Names,Accuracy)\n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax2.bar(Names,F1_Sc)\n",
    "ax2.set_title(\"F1-Score\")\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmwK0eyGZsbt"
   },
   "source": [
    "## **Επίδοση με βελτιστοποιήσεις**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFTQKyJDZgGm"
   },
   "source": [
    "Θα εφαρμόσουμε ορισμένους μετασχηματισμούς στο dataset για χρήση στους ταξινομητές. Για την κατασκευή του μοντέλου θα βασιστούμε στην κλάση Pipeline του πακέτου imbalanced-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2909,
     "status": "ok",
     "timestamp": 1639328154603,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "tPI7hJroSpkm",
    "outputId": "d81124a9-2e34-4b6d-834b-58f90f0ff18a"
   },
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5stm5ZfcSu_1"
   },
   "source": [
    "Επίσης θα χρησιμοποιήσουμε διάφορες κλάσεις του πακέτου **scikit-learn** για την προεπεξεργασία των δεδομένων. Συγκεκριμένα θα χρησιμοποιήσουμε τις κλάσεις:\n",
    "\n",
    "*   **VarianceThreshold** : Αφαιρεί τα χαρακτηριστικά στο training set που έχουν μηδενική διακύμανση (default) ή πολύ χαμηλή. Σε γενικές γραμμές αν η διακύμανση ενός χαρακτηριστικού εισόδου είναι πολύ χαμηλή, δεν μπορεί να προσφέρει σημαντικά στη διαχωριστική ικανότητα του ταξινομητή. Ειδικά στην περίπτωση που η διακύμανση είναι 0, δηλαδή το χαρακτηριστικό έχει σταθερή τιμή για όλα τα δείγματα εκπαίδευσης, δεν χρησιμεύει καθόλου στον ταξινομητή για να αποφασίσει αν ένα δείγμα ανήκει σε μία κλάση ή σε μια άλλη και επιπλέον μπορεί να δυσκολέψει άλλες διαδικασίες της προεπεξεργασίας όπως η κανονικοποίηση των χαρακτηριστικών.\n",
    "*   **StandardScaler**: Θα εκτελέσει κανονικοποίηση των δειγμάτων (μέση τιμή μ=0 και διασπορά σ$^{2}$ =1) με βάση τα δείγματα εκπαίδευσης.\n",
    "*   **PCA**: Εφαρμόζουμε εξαγωγή νέων χαρακτηριστικών σε ένα χώρο μικρότερων διαστάσεων (feature extraction) με την ανάλυση σε κύριες συνιστώσες (Principal Components Analysis). Με την μέθοδο αυτή, αναλύουμε τα δεδομένα σε κύριες συνιστώσες και δουλέυουμε με τελείως νέες, γραμμικά ασυσχέτιστες μεταβλητές μικρότερης διαστατικότητας. Η αναγκη μείωσης των χαρακτηριστικών έγκειται στο γεγονός ότι η απόδοση του μοντέλου αυξάνεται όταν τα δεδομένα εκπαίδευσης ειναι μεγαλύτερα σε μέγεθος και καλύτερα σε ποιότητα, αλλά μειώνεται όταν αυξάνονται οι διαστάσεις του dataset, δηλαδή ο αριθμός των χαρακτηριστικών. Το φαινόμενο αυτό είναι γνωστό ως κατάρα της διαστατικότητας (Curse of dimensionality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zizc6JsOYjUO"
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "Classifiers = [DummyClassifier(),GaussianNB(),KNeighborsClassifier(),LogisticRegression(),MLPClassifier(),SVC()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtR0o6n_xie6"
   },
   "source": [
    "Σε αντίθεση με πριν, σε αυτό το στάδιο θα εξετάσουμε και τις τιμές των υπερπαραμέτρων των ταξινομητών ως προς ποιές παρέχουν την βέλτιστη απόδοση. Αυτό θα το επιτύχουμε με την τεχνική του Cross-Validation και συγκεκριμένα της κλάσης GridSearchCV του scikit-learn. Ουσιαστικά θα δοκιμάσουμε διάφορους συνδυασμούς, θα εκπαίδευσουμε το μοντέλο σε κάθε περίπτωση με Cross-Validation και θα κρατήσουμε τον ταξινομητή, που κρίνει η κλάση GridSearchCV, ότι είναι καλύτερος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYEjJOGz0QiP",
    "outputId": "23af28af-8b95-420d-f816-9b7a0bcfa082"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_variance = np.array(X_train).var(axis=0)\n",
    "print(train_variance)\n",
    "print(np.max(train_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VjPrFf9_LAh"
   },
   "source": [
    "Προσαρμόζουμε τις τιμές μας στο variance που παρατηρήσαμε:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J99e5ezvyfB9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "vthreshold = [0, 1, 5,10] # Variance Thresholds\n",
    "n_components = [5,20, 50, 60] # PCA\n",
    "scores = ['accuracy','f1_macro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DDfpUHlL0g4"
   },
   "source": [
    "Στην συνέχεια θα περάσουμε το dataset μεσω του Pipeline για προεπεξεργασία και θα εκτελέσουμε 10-Fold Cross-Validation με κάθε ταξινομητή για να βρούμε τις βέλτιστες παραμέτρους για τους μετασχηματιστές και τον ταξινομητή:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VVsBN4XMMkX"
   },
   "source": [
    "**Dummy Classifier με παράμετρο την στρατηγική εκτίμησης προβλέψεων:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61845,
     "status": "ok",
     "timestamp": 1639328216779,
     "user": {
      "displayName": "Χρήστος Ζαχαριουδάκης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLiqi_VlzO8OYG4UpGsS3N8zUB09CFdSWyHyBJdA=s64",
      "userId": "00755196409078902280"
     },
     "user_tz": -120
    },
    "id": "oxgXM4b8M4Ny",
    "outputId": "1d935fd5-0517-48ab-f91e-6ea6af9f96f8"
   },
   "outputs": [],
   "source": [
    " # Classifier Parameters\n",
    "strategy = [\"stratified\", \"most_frequent\", \"prior\", \"uniform\", \"constant\"] \n",
    "\n",
    "for score in scores:\n",
    "  clf = DummyClassifier()  \n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('DM', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, DM__strategy=strategy), cv=10, scoring=score)\n",
    "  #print(estimator.get_params())    \n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgp3hShdMThE"
   },
   "source": [
    "**Gaussian Naive Bayes Classifier με παράμετρο το ποσοστό της μεγαλύτερης διασποράς που προστίθεται στις διασπορές των δειγμάτων για σταθερότητα των υπολογισμών:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiLJ7xAOMtHv",
    "outputId": "1d8331e2-7a46-4e73-f2c1-33f913bc91ac"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "var_smoothing = [1e-9, 1e-8, 1e-6, 1e-4, 1e-2, 1e-1]  \n",
    "\n",
    "for score in scores:\n",
    "  clf = GaussianNB()  \n",
    "\n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, GNB__var_smoothing=var_smoothing), cv=10, scoring=score)\n",
    "  #print(estimator.get_params())    \n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwwGxqLzMTj6"
   },
   "source": [
    "**K-Nearest Neighbors Classifier με παράμετρο τον αριθμό των γειτονικών δειγμάτων που εξετάζονται για να παρθεί η απόφαση για την ταξινόμηση:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKI99o1vMxWj",
    "outputId": "f288f506-f1eb-4551-eaea-45e00c3141ff"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "k = [1, 3, 5, 11, 21, 31] \n",
    "\n",
    "for score in scores:  \n",
    "  clf = KNeighborsClassifier()\n",
    "\n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('kNN', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, kNN__n_neighbors=k), cv=10, scoring=score)\n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UycWTjGdMTm1"
   },
   "source": [
    "**Logistic Regression Classifier με παράμετρο την μέθοδο regularization και το βάρος C των λανθασμένων ταξινομήσεων :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXYqtkKUM6wR",
    "outputId": "aea69204-55c4-4075-ebf4-3a3b6d4ccadc"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "penalty = ['l1','l2' 'elasticnet', 'none']\n",
    "C = [0,1,2,5,10]\n",
    "\n",
    "for score in scores:\n",
    "  clf = LogisticRegression()\n",
    "\n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('LR', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, LR__penalty=penalty,LR__C = C), cv=10, scoring=score)\n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iuOPp_WMUHO"
   },
   "source": [
    "**Multi-Layer Perceptron Classifier με παραμέτρους:**\n",
    "\n",
    "*   Συνάρτηση ενεργοποίησης (activation function)\n",
    "*   Βελτιστοποιητης (Optimizer)\n",
    "*   Μέγεθος batch\n",
    "*   Τιμή ρυθμού μάθησης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l0ejTH2IM8u0",
    "outputId": "39b27378-fb7e-40c9-a117-d87552705d2b"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "activation = ['logistic','relu']\n",
    "optimizer = ['adam']\n",
    "batch_size = ['auto',200]\n",
    "lr_val = [0.001,0.01]\n",
    "\n",
    "for score in scores:\n",
    "  clf = MLPClassifier()\n",
    "\n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('MLP', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, MLP__activation = activation, MLP__solver = optimizer,MLP__batch_size = batch_size,MLP__learning_rate_init = lr_val), cv=10, scoring=score)\n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O υπολογισμός του καλύτερου MLPClassifier καθυστερεί αρκετά, λόγω του πλήθους των υπερπαραμέτρων και της πολυπλοκότητας του μοντέλου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsABUVj6MUOe"
   },
   "source": [
    "**Support Vector Machines Classifier με παραμέτρους το βάρος C των λανθασμένων ταξινομήσεων, τον τύπο συνάρτηση πυρήνα και τον συντελεστή γ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky9z3rjaLqy2"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "C = [0,1,2,5,10]\n",
    "kernel =['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale', 'auto'] \n",
    "\n",
    "for score in scores:\n",
    "  clf = SVC()\n",
    "\n",
    "  pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVM', clf)], memory = 'tmp')\n",
    "  estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, SVM__C = C , SVM__kernel = kernel,SVM__gamma = gamma), cv=10, scoring=score)\n",
    "\n",
    "  estimator.fit(X_train, y_train)\n",
    "  print(estimator.best_estimator_)\n",
    "  print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_Mx4-nsckTq"
   },
   "source": [
    "Με βάση τα παραπάνω αποτελέσματα οι καλύτερες τιμές παραμέτρων, με βάση την μετρική **accuracy**, για κάθε ταξινομητή είναι:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIMJPtMQfqcV"
   },
   "source": [
    "| Ταξινομητές | Παράμετροι |\n",
    "| --- | --- |\n",
    "| Dummy | {'DM__strategy': 'stratified', 'pca__n_components': 60, 'selector__threshold': 0} |\n",
    "| Gaussian Naive Bayes | {'GNB__var_smoothing': 0.01, 'pca__n_components': 60, 'selector__threshold': 0} |\n",
    "| K-Neighbors | {'kNN__n_neighbors': 3, 'pca__n_components': 20, 'selector__threshold': 5} |\n",
    "| Logistic Regression | {'LR__C': 0, 'LR__penalty': 'none', 'pca__n_components': 60, 'selector__threshold': 0} | \n",
    "| Multi-Layer Perceptron | {'MLP__activation': 'relu', 'MLP__batch_size': 'auto', 'MLP__learning_rate_init': 0.001, 'MLP__solver': 'adam', 'pca__n_components': 20, 'selector__threshold': 5} | \n",
    "| SVM | {'SVM__C': 2, 'SVM__gamma': 'scale', 'SVM__kernel': 'rbf', 'pca__n_components': 20, 'selector__threshold': 5} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqGy_N9Hcr9J"
   },
   "source": [
    "Με βάση τα παραπάνω αποτελέσματα οι καλύτερες τιμές παραμέτρων, με βάση την μετρική **F1-macro**, για κάθε ταξινομητή είναι:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbkqgZQscvgp"
   },
   "source": [
    "| Ταξινομητές | Παράμετροι |\n",
    "| --- | --- |\n",
    "| Dummy | {'DM__strategy': 'stratified', 'pca__n_components': 5, 'selector__threshold': 10} |\n",
    "| Gaussian Naive Bayes | {'GNB__var_smoothing': 0.01, 'pca__n_components': 60, 'selector__threshold': 0} |\n",
    "| K-Neighbors | {'kNN__n_neighbors': 3, 'pca__n_components': 20, 'selector__threshold': 5}|\n",
    "| Logistic Regression | {'LR__C': 0, 'LR__penalty': 'none', 'pca__n_components': 60, 'selector__threshold': 0} | \n",
    "| Multi-Layer Perceptron | {'MLP__activation': 'relu', 'MLP__batch_size': 200, 'MLP__learning_rate_init': 0.001, 'MLP__solver': 'adam', 'pca__n_components': 50, 'selector__threshold': 1} | \n",
    "| SVM | {'SVM__C': 2, 'SVM__gamma': 'scale', 'SVM__kernel': 'rbf', 'pca__n_components': 20, 'selector__threshold': 5} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B2eHEeXdgaD"
   },
   "source": [
    "Οι καλύτερες παράμετροι για τις δύο μετρικές είναι ίδιες με εξαίρεση τους Dummy και MLP classifiers. Στην συνέχεια λοιπον θα χρησιμοποιήσουμε τους καλύτερους ταξινομητές με βάση την μετρική **F1-Macro**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyIxC-2wfPf-"
   },
   "source": [
    "**Dummy Classifier με παράμετρο την στρατηγική εκτίμησης προβλέψεων:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGvJT7ITfPf-",
    "outputId": "2517330b-e9fc-4fed-a31c-46385bd4a7f9"
   },
   "outputs": [],
   "source": [
    "print(\"Dummy Classifier\")\n",
    "\n",
    "Accuracy_best = []\n",
    "F1_sc_best = []\n",
    "\n",
    "# Classifier Parameters\n",
    "strategy = [\"stratified\"] \n",
    "vthreshold = [10] # Variance Thresholds\n",
    "n_components = [5] # PCA\n",
    "\n",
    "clf = DummyClassifier()  \n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('DM', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, DM__strategy=strategy), cv=10, scoring=\"f1_macro\")  \n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsuM1GskfPf_"
   },
   "source": [
    "**Gaussian Naive Bayes Classifier με παράμετρο το ποσοστό της μεγαλύτερης διασποράς που προστίθεται στις διασπορές των δειγμάτων για σταθερότητα των υπολογισμών:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8pZeSDQfPf_",
    "outputId": "e853f197-4cc8-46c7-9088-d8d95de48d8f"
   },
   "outputs": [],
   "source": [
    "print(\"Gaussian Naive Bayes Classifier\")\n",
    "\n",
    "# Classifier Parameters\n",
    "var_smoothing = [1e-1]  \n",
    "vthreshold = [0] # Variance Thresholds\n",
    "n_components = [60] # PCA\n",
    "\n",
    "clf = GaussianNB()  \n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, GNB__var_smoothing=var_smoothing), cv=10, scoring='f1_macro')\n",
    "#print(estimator.get_params())    \n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "  \n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHmYa7CZfPf_"
   },
   "source": [
    "**K-Nearest Neighbors Classifier με παράμετρο τον αριθμό των γειτονικών δειγμάτων που εξετάζονται για να παρθεί η απόφαση για την ταξινόμηση:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFcAyO-1fPf_",
    "outputId": "ab259fe3-0946-40aa-8166-8b65d848a91b"
   },
   "outputs": [],
   "source": [
    "print(\"K-Nearest Neighbors Classifier\")\n",
    "\n",
    "# Classifier Parameters\n",
    "k = [3]\n",
    "vthreshold = [5] # Variance Thresholds\n",
    "n_components = [20] # PCA\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('kNN', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, kNN__n_neighbors=k), cv=10, scoring=\"f1_macro\")\n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "  \n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCa6UDzIfPf_"
   },
   "source": [
    "**Logistic Regression Classifier με παράμετρο την μέθοδο regularization και το βάρος C των λανθασμένων ταξινομήσεων :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COBq3x-rfPf_",
    "outputId": "7e5b256a-056c-4fbb-b708-29c43cef8225"
   },
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Classifier\")\n",
    "\n",
    "# Classifier Parameters\n",
    "penalty = ['none']\n",
    "C = [0]\n",
    "vthreshold = [0] # Variance Thresholds\n",
    "n_components = [60] # PCA\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('LR', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, LR__penalty=penalty,LR__C = C), cv=10, scoring='f1_macro')\n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "  \n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-VXAVPUfPf_"
   },
   "source": [
    "**Multi-Layer Perceptron Classifier με παραμέτρους:**\n",
    "\n",
    "*   Συνάρτηση ενεργοποίησης (activation function)\n",
    "*   Βελτιστοποιητης (Optimizer)\n",
    "*   Μέγεθος batch\n",
    "*   Τιμή ρυθμού μάθησης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCreU58jfPgA",
    "outputId": "1ff58bbb-7e8f-4d4d-b7f0-08c3505e8be2"
   },
   "outputs": [],
   "source": [
    "print(\"MLP Classifier\")\n",
    "\n",
    "# Classifier Parameters\n",
    "activation = ['relu']\n",
    "optimizer = ['adam']\n",
    "batch_size = [200]\n",
    "lr_val = [0.001]\n",
    "vthreshold = [1] # Variance Thresholds\n",
    "n_components = [50] # PCA\n",
    "\n",
    "clf = MLPClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('MLP', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, MLP__activation = activation, MLP__solver = optimizer,MLP__batch_size = batch_size,MLP__learning_rate_init = lr_val), cv=10, scoring='f1_macro')\n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMGCPftGfPgA"
   },
   "source": [
    "**Support Vector Machines Classifier με παραμέτρους το βάρος C των λανθασμένων ταξινομήσεων, τον τύπο συνάρτηση πυρήνα και τον συντελεστη γ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMoqcd0tfPgA",
    "outputId": "4aab7d13-aa39-4ec1-c8b6-14dd596fdd56"
   },
   "outputs": [],
   "source": [
    "# Classifier Parameters\n",
    "vthreshold = [5] # Variance Thresholds\n",
    "n_components = [20] # PCA\n",
    "C = [2]\n",
    "kernel =['rbf']\n",
    "gamma = ['scale'] \n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVM', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, SVM__C = C , SVM__kernel = kernel,SVM__gamma = gamma), cv=10, scoring='f1_macro')\n",
    "\n",
    "start = time.time()\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Train time is :\",time.time()-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = estimator.predict(X_test)\n",
    "print(\"Test time is :\",time.time()-start,\"seconds\")\n",
    "  \n",
    "acc = accuracy_score(y_test, preds) * 100\n",
    "f1 = f1_score(y_test, preds, average='macro') * 100\n",
    "Accuracy_best.append(acc)\n",
    "F1_sc_best.append(f1)\n",
    "print(\"Accuracy is {}%\".format(acc))\n",
    "print(\"F1-Macro is {}%\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQDOCDHwiLx4"
   },
   "source": [
    "Σε αυτό το σημείο θα παρουσιάσουμε συνοπτικά και συγκριτικά την επίδοση των ταξινομητών για τις καλύτερες παραμέτρους τους σε σχέση με την out-of-the-box επίδοσή τους."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUS8yc7fiLx4"
   },
   "source": [
    "| Ταξινομητές | Accuracy (OOTB) | Accuracy (Best) |Μεταβολή accuracy| F1-Score (OOTB) | F1-Score (Best) | Μεταβολή F1-Score|Training time (Best) | Testing time (Best) | \n",
    "| --- | --- | --- | --- | --- |--- | --- |--- | --- |\n",
    "| Dummy | 8.17% | 10.33% |+2.16% | 1.51% | 10.23% |+8.72% | 0.27s| 0.002s  |\n",
    "| Gaussian Naive Bayes | 94.83%  | 92%|-2.83%| 94.93% |92.03%  |-2.90%|0.33s |0.003s  |\n",
    "| K-Neighbors | 97.83% | 96.66% |-2.17%| 97.79% |96.60%  |-1.19%|0.32s |0.023s  |\n",
    "| Logistic Regression | 95.67% | 91.66% |-4.01%| 95.59% |91.55%  |-4.04%|0.567s |0.002s  |\n",
    "| Multi-Layer Perceptron |  97.33% |96.83%  |-1.33%| 97.41%  | 96.80% |-1.45%|10.42s | 0.003s |\n",
    "| SVM |  98.17% | 97.5% |-1.67%| 98.13% |97.53%  |-0.6%|0.68s |0.039s  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eHgIA1ZiLx4",
    "outputId": "6ed12f4c-4a6b-4092-98a3-7549893f0d0a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle('Metrics on train set')\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "x = np.arange(len(Names))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "difference = [list1_i-list2_i for list1_i, list2_i in zip(Accuracy, Accuracy_best)]\n",
    "\n",
    "rects1 = ax1.bar(x,Accuracy,width,label = \"OOTB\")\n",
    "rects2 = ax1.bar(x + width,Accuracy_best,width,label = \"Best\")\n",
    "rects5 = ax1.bar(x + 2*width,difference,width,label = \"Difference\")\n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(Names)\n",
    "ax1.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects5)\n",
    "\n",
    "difference = [list1_i-list2_i for list1_i, list2_i in zip(F1_Sc, F1_sc_best)]\n",
    "\n",
    "rects3 = ax2.bar(x,F1_Sc,width,label = \"OOTB\")\n",
    "rects4 = ax2.bar(x + width,F1_sc_best,width,label = \"Best\")\n",
    "rects6 = ax2.bar(x + 2*width,difference,width,label = \"Difference\")\n",
    "ax2.set_title(\"F1-Score\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(Names)\n",
    "ax2.legend()\n",
    "\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lts5RhW0iLx5"
   },
   "source": [
    "Αντίθετα από ότι αναμέναμε, παρατηρούμε μια ελαφρία μείωση στην απόδοση σε κάθε ταξινομητή. Μια ερμηνεία για αυτό το φαινόμενο είναι οτι η εφαρμογή μετασχηματισμών στα δεδομένα μας, αφαίρεσε πληροφορία χρήσιμη για την ταξινόμηση των δειγμάτων. Ο καλύτερος ταξινομήτης και στις δύο περιπτώσεις, με βάση αμφότερες μετρικές, είναι ο **SVM (με kernel = \"rbf\")** και ο χειρότερος, με εξαίρεση τον Dummy, είναι ο **Gaussian Naive Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-YDAuA7iLx5"
   },
   "source": [
    "Σε ότι αφορά τους χρόνους, ο χρόνος εκπαίδευσης είναι πάντα μεγαλύτερος του χρόνου δοκιμής. Αυτό είναι λογικό, καθως στην εκπαίδευση, το μοντέλο πρέπει να μάθει την κατανομή των δειγμάτων, ενώ στην δοκιμή εκτελεί προβλέψεις με βάση αυτά που έχει μάθει. Ο μεγαλύτερος χρόνος εκπαίδευσης ανήκει στο MLP classifier. Επίσης είναι αναμενόμενο, καθώς είναι ο πιο σύνθετος από τους ταξινομητές που χρησιμοποιήσαμε."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl_dxEUaiLx5"
   },
   "source": [
    "Στη συνέχεια, θα σχεδιάσουμε τους πίνακες σύγχυσης για αυτούς τους δύο ταξινομητές, με χρήση του πακέτου **seaborn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJSQVvHziLx5",
    "outputId": "edfbb030-40eb-4d20-b261-64733a166b6d"
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuQWkbEXiLx5",
    "outputId": "86a25203-ed03-4cd0-b7ef-22a686920234"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"################### SVM #############################\")\n",
    "vthreshold = [5] # Variance Thresholds\n",
    "n_components = [20] # PCA\n",
    "C = [2]\n",
    "kernel =['rbf']\n",
    "gamma = ['scale'] \n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('SVM', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, SVM__C = C , SVM__kernel = kernel,SVM__gamma = gamma), cv=10, scoring=score)\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "best = estimator.predict(X_test)\n",
    "\n",
    "conf_best = confusion_matrix(y_test, best)\n",
    "print(conf_best,end='\\n')\n",
    "\n",
    "print(\"################### GNB #############################\")\n",
    "\n",
    "# Classifier Parameters\n",
    "var_smoothing = [1e-1]  \n",
    "vthreshold = [0] # Variance Thresholds\n",
    "n_components = [60] # PCA\n",
    "\n",
    "clf = GaussianNB()  \n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('pca', pca), ('GNB', clf)], memory = 'tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, GNB__var_smoothing=var_smoothing), cv=10, scoring='f1_macro')\n",
    "#print(estimator.get_params())    \n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "worst = estimator.predict(X_test)\n",
    "\n",
    "conf_worst = confusion_matrix(y_test, worst)\n",
    "print(conf_worst,end='\\n')\n",
    "\n",
    "fig, axs = plt.subplots(1,2,constrained_layout=True)\n",
    "fig.suptitle('Confusion matrices')\n",
    "sns.heatmap(conf_worst,ax = axs[0])\n",
    "axs[0].set_title('GNB confusion matrix')\n",
    "sns.heatmap(conf_best,ax = axs[1])\n",
    "axs[1].set_title('SVM confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytNb_HMCiLx5"
   },
   "source": [
    "Επειδή και οι δύο αλγόριθμοι αποδίδουν πολύ καλά (άνω του 90%), οι πίνακες σύγχυσής τους είναι όμοιοι και διαγώνιοι, ειδικά ο SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQrADrZ2iLx6"
   },
   "source": [
    "Από την παραπάνω μελέτη, ο καλύτερος ταξινομητής και αυτός που θα προτίμαμε τελικά για το συγκεκριμένο dataset, είναι ο SVM με kernel 'rbf', ο οποίος μας δίνει μέγιστο accuracy και F1-Score, 98.17% και 98.13% αντίστοιχα, ποσοστά εξαιρετικά κοντά στο 100%. Ένας λόγος που αποδίδει καλά, είναι επειδή εξ ορισμού, αποδίδει καλά σε datasets με μεγάλο αριθμό χαρακτηριστικών, όπως αυτό που χρησιμοποιήσαμε στην παρούσα άσκηση."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachineLearning_Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
